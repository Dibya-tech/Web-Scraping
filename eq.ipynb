{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGDACS ID WF 1020968\\nCountries Australia\\nEvent summary This forest fire is expected to have a low humanitarian impact based on the magnitude and the affected population and their vulnerability.\\nGDACS ID\\tWF 1020968\\nCountries:\\tAustralia\\nStart Date - Last detection*:\\t09 Aug 2024 - 14 Aug 2024\\nDuration (days):\\t5\\nPeople affected:\\t0 in the burned area\\nBurned area:\\t10556 ha\\n\\n\\nDynamically store the cols and pass the Xpath into a list element\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "GDACS ID WF 1020968\n",
    "Countries Australia\n",
    "Event summary This forest fire is expected to have a low humanitarian impact based on the magnitude and the affected population and their vulnerability.\n",
    "GDACS ID\tWF 1020968\n",
    "Countries:\tAustralia\n",
    "Start Date - Last detection*:\t09 Aug 2024 - 14 Aug 2024\n",
    "Duration (days):\t5\n",
    "People affected:\t0 in the burned area\n",
    "Burned area:\t10556 ha\n",
    "\n",
    "\n",
    "Dynamically store the cols and pass the Xpath into a list element\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Dataframes\n",
    "# Main table\n",
    "table_0_headers = ['Event_id','Episode','Event_type','Impact_url']\n",
    "table_1_headers = ['Event_id','Episode','Countries','Start_date_last_detected','Duration','People_affected','Burned_area','Event_summary']\n",
    "table_2_headers = ['Event_id','Episode','ID','Alert_Color','GDACS_Score','Population_Affected','Burned_Area','Last_Update','GWIS']\n",
    "table_3_headers = ['Event_id','Episode','Radius','Population']\n",
    "table_4_headers = ['Event_id','Episode','Region_province','Country','Population']\n",
    "table_5_headers = ['Event_id','Episode','Name','Region_Province','Country','City_class','Population','Distance']\n",
    "table_6_headers = ['Event_id','Episode','Name','IATA_Code','Elevation_in_m','Usage','Runway_type','IFR','Runway_Length_in_ft','Distance']\n",
    "table_7_headers = ['Event_id','Episode','Name','LOCODE','Country','Distance']\n",
    "table_8_headers = ['Event_id','Episode','Reservoir','Dam_Name','River','Year','Distance']\n",
    "table_9_headers = ['Event_id','Episode','Name','Country','Reactor','Distance']\n",
    "\n",
    "len(table_1_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004452 10 Wildfires\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "html_file = \"file:///F:/Web Scraping/latest_htmls/Wildfires/1004452_10_Wildfires_WF.html\"\n",
    "# \"file:///F:/Web Scraping/htmls/Wildfires/1020968_8_Wildfires_WF.html\"\n",
    "# https://www.gdacs.org/Wildfires/report.aspx?eventtype=WF&eventid=1004452&episodeid=10\n",
    "# \"file:///F:/Web Scraping/latest_htmls/Wildfires/1021646_9_Wildfires_WF.html\"\n",
    "# \"file:///F:/Web Scraping/htmls/Wildfires/1.html\"\n",
    "# \"https://www.gdacs.org/Wildfires/report.aspx?eventtype=WF&eventid=1019635&episodeid=2\"\n",
    "# Open the URL\n",
    "file_name = html_file.split('/')[-1].split('.')[0]\n",
    "event_id,episode,event_type = file_name.split('_')[0:3]\n",
    "\n",
    "print(event_id,episode,event_type)\n",
    "# event_type = file_name[1].split('/')[1]\n",
    "# episode = file_name[2]\n",
    "# print(file_name,event_id,event_type,episode)\n",
    "driver.get(html_file)\n",
    "\n",
    "# event_id = '1021461'\n",
    "# event_type = 'wildfires'\n",
    "# episode = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Table 1\n",
    "# Fetch the event summary section\n",
    "try:\n",
    "    event_path = '//*[@class=\"p_summary\"][1]'\n",
    "    event_summary_element = driver.find_element(By.XPATH, event_path)\n",
    "    event_summary_text = event_summary_element.text\n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{event_path}' not found.\")\n",
    "# table_1_df =[]\n",
    "# try:\n",
    "#     table_xpath = '//*[@id=\"alert_summary_left\"]/table/tbody'  # Adjust XPath as needed\n",
    "#     table = driver.find_element(By.XPATH, table_xpath)\n",
    "#     # Fetch table rows using XPath\n",
    "#     rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "#     rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "#     # Extract data from each row and column\n",
    "#     table_data = []\n",
    "#     for row in rows:\n",
    "#         columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "#         columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "#         row_data = [column.text for column in columns]\n",
    "#         if len(row_data) <1:\n",
    "#             continue\n",
    "#         else:\n",
    "#             table_data.append(row_data)\n",
    "\n",
    "#     table_1_df = [\n",
    "#         event_id,\n",
    "#         episode,\n",
    "#         *[table_data[i][1] for i in range(1, 6)],\n",
    "#         event_summary_text\n",
    "#     ]\n",
    "#     print(table_1_df)\n",
    "# except NoSuchElementException:\n",
    "#     print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004452', '10', 'Republic of Korea', '04 Mar 2022 - 12 Mar 2022', '8', '1580 in the burned area', '19748 ha', 'This forest fire is expected to have a low humanitarian impact based on the magnitude and the affected population and their vulnerability.']\n"
     ]
    }
   ],
   "source": [
    "# table 1\n",
    "table_1_df =[]\n",
    "try:\n",
    "    table_xpath = '//*[@id=\"alert_summary_left\"]/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "\n",
    "    # for i in range(len(table_data)):\n",
    "    row = [\n",
    "        event_id,\n",
    "        episode,\n",
    "        *[table_data[i][1] for i in range(1, 6)],\n",
    "        event_summary_text\n",
    "    ]\n",
    "    table_1_df.append(row)\n",
    "    # table_1_df = [\n",
    "    #     event_id,\n",
    "    #     episode,\n",
    "    #     *[table_data[i][1] for i in range(1, 6)],\n",
    "    #     event_summary_text\n",
    "    # ]\n",
    "    for row in table_1_df:\n",
    "        print(row)\n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004452', '10', '1', '', '0.5', '1044', '7992', '05 Mar 2022 04:01', 'GWIS']\n",
      "['1004452', '10', '2', '', '0.5', '1044', '8053', '05 Mar 2022 11:37', 'GWIS']\n",
      "['1004452', '10', '3', '', '0.5', '1539', '12682', '06 Mar 2022 04:01', 'GWIS']\n",
      "['1004452', '10', '4', '', '0.5', '1570', '15222', '07 Mar 2022 04:01', 'GWIS']\n",
      "['1004452', '10', '5', '', '0.5', '1580', '17363', '08 Mar 2022 04:01', 'GWIS']\n",
      "['1004452', '10', '6', '', '0.5', '1570', '18099', '09 Mar 2022 04:01', 'GWIS']\n",
      "['1004452', '10', '7', '', '0.5', '1580', '18435', '10 Mar 2022 04:00', 'GWIS']\n",
      "['1004452', '10', '8', '', '0.5', '1580', '19387', '11 Mar 2022 04:00', 'GWIS']\n",
      "['1004452', '10', '9', '', '0.5', '1633', '19728', '12 Mar 2022 04:00', 'GWIS']\n",
      "['1004452', '10', '10', '', '0.5', '1580', '19748', '13 Mar 2022 04:00', 'GWIS']\n"
     ]
    }
   ],
   "source": [
    "# table 2\n",
    "table_2_df = []\n",
    "try:\n",
    "    # Locate the Impact Timeline\n",
    "    table_xpath = '//*[@id=\"ctl00_CPH_GridViewEpisodes\"]/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:7] \n",
    "        ]\n",
    "        table_2_df.append(row)\n",
    "\n",
    "    for row in table_2_df:\n",
    "        print(row)\n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004452', '10', 'Radius', 'Population']\n",
      "['1004452', '10', '10 km', '32000 people']\n",
      "['1004452', '10', '5 km', '27000 people']\n",
      "['1004452', '10', '2 km', '20000 people']\n",
      "['1004452', '10', '1 km', '11000 people']\n",
      "['1004452', '10', 'Burned Area', '1600 people']\n"
     ]
    }
   ],
   "source": [
    "table_3_df = []\n",
    "try:\n",
    "    # Locate the Exposed population\n",
    "    table_xpath = '//*[@id=\"graph_eq\"]/table/tbody/tr/td/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/th | .//td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "\n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:2] \n",
    "        ]\n",
    "        table_3_df.append(row)\n",
    "\n",
    "    for row in table_3_df:\n",
    "        print(row)\n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004452', '10', 'Kyongsang-bukto', 'Republic of Korea', '2.9 million people']\n",
      "['1004452', '10', 'Kangwon-do', 'Republic of Korea', '1.6 million people']\n"
     ]
    }
   ],
   "source": [
    "# Table 4\n",
    "table_4_df = []\n",
    "try:\n",
    "    # Locate the Affected Provinces\n",
    "    table_xpath = '//*[@id=\"provinces\"]/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "\n",
    "        \n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:3] \n",
    "        ]\n",
    "        table_4_df.append(row)\n",
    "\n",
    "    for row in table_4_df:\n",
    "        print(row)\n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait = WebDriverWait(driver, 10)\n",
    "# btn = wait.until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"cookie-consent-banner\"]/div/div/div[2]/a[1]')))\n",
    "# btn.click()\n",
    "# scroll_script = \"window.scrollTo(0, document.body.scrollHeight * 0.7);\"\n",
    "# driver.execute_script(scroll_script) \n",
    "# time.sleep(10)\n",
    "# btn = wait.until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"airports\"]/div/div[1]')))\n",
    "# btn.click()\n",
    "# btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004452', '10', 'Yeongweol', 'Kang-Won-Do', 'Republic of Korea', 'City', '26000 people', '74 km']\n",
      "['1004452', '10', 'Andong', 'Kyongsangbuk-Do', 'Republic of Korea', 'City', '130000 people', '75 km']\n",
      "['1004452', '10', 'Gangneung', 'Kang-Won-Do', 'Republic of Korea', 'City', '-', '85 km']\n",
      "['1004452', '10', 'Yecheon', 'Kyongsangbuk-Do', 'Republic of Korea', 'City', '-', '89 km']\n"
     ]
    }
   ],
   "source": [
    "table_5_df = []\n",
    "try:\n",
    "    # Locate the Affected populated places\n",
    "    table_xpath = '//*[@id=\"cities\"]/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text.strip() for column in columns]\n",
    "        # row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "        \n",
    "        \n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:6] \n",
    "        ]\n",
    "        table_5_df.append(row)\n",
    "\n",
    "    for row in table_5_df:\n",
    "        print(row)\n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004452', '10', 'R 430', '', '2', '', '', '', '0', '39 km']\n",
      "['1004452', '10', 'Samchok', 'SUK', 'unknown', '', '', '', '0', '46 km']\n",
      "['1004452', '10', 'Gangneung', 'KAG', '11', 'Mil.', 'Paved', 'Yes', '8900', '83 km']\n",
      "['1004452', '10', 'R 418', '', '283', '', '', '', '0', '87 km']\n",
      "['1004452', '10', 'R 417', '', '525', '', '', '', '0', '92 km']\n"
     ]
    }
   ],
   "source": [
    "table_6_df = []\n",
    "try:\n",
    "    # Table 6\n",
    "    # Locate the airports\n",
    "    table_xpath = '//*[@id=\"airports\"]/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text.strip() for column in columns]\n",
    "        # row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "        \n",
    "        \n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:8] \n",
    "        ]\n",
    "        table_6_df.append(row)\n",
    "\n",
    "    for row in table_6_df:\n",
    "        print(row)\n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004452', '10', 'Ulchin', '', 'South Korea', '14 km']\n",
      "['1004452', '10', 'Tonghae', 'KRTGH', 'South Korea', '50 km']\n",
      "['1004452', '10', 'Mukho', 'KRMUK', 'South Korea', '56 km']\n"
     ]
    }
   ],
   "source": [
    "# Table 7\n",
    "# Locate the ports\n",
    "table_7_df = []\n",
    "try:\n",
    "    table_xpath = '//*[@id=\"ports\"]/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text.strip() for column in columns]\n",
    "        # row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "        \n",
    "        \n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:4] \n",
    "        ]\n",
    "        table_7_df.append(row)\n",
    "\n",
    "    for row in table_7_df:\n",
    "        print(row)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', 'Imha', 'Panbyon', '1993', '69 km'], ['', 'An Dong', 'Nakdong', '1977', '71 km'], ['', 'Toam', 'Song', 'n/a', '80 km']]\n",
      "['1004452', '10', '', 'Imha', 'Panbyon', '1993', '69 km']\n",
      "['1004452', '10', '', 'An Dong', 'Nakdong', '1977', '71 km']\n",
      "['1004452', '10', '', 'Toam', 'Song', 'n/a', '80 km']\n"
     ]
    }
   ],
   "source": [
    "table_8_df = []\n",
    "# Table 8\n",
    "# Locate the dams\n",
    "try:\n",
    "    table_xpath = '//*[@id=\"dams\"]/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text.strip() for column in columns]\n",
    "        # row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "    print(table_data)\n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:5] \n",
    "        ]\n",
    "        table_8_df.append(row)\n",
    "\n",
    "    for row in table_8_df:\n",
    "        print(row)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ULCHIN', 'REPUBLIC OF KOREA', '6', '8 km']]\n",
      "['1004452', '10', 'ULCHIN', 'REPUBLIC OF KOREA', '6', '8 km']\n"
     ]
    }
   ],
   "source": [
    "table_9_df = []\n",
    "# Table 9\n",
    "# Locate the nuclear plants\n",
    "try:\n",
    "    table_xpath = '//*[@id=\"nuclear\"]/table/tbody'  # Adjust XPath as needed\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    # Fetch table rows using XPath\n",
    "    rows_xpath = './/tr'  # XPath to locate rows within the table\n",
    "    rows = table.find_elements(By.XPATH, rows_xpath)\n",
    "    # Extract data from each row and column\n",
    "    table_data = []\n",
    "    for row in rows:\n",
    "        columns_xpath = './/td'  # XPath to locate columns within each row\n",
    "        columns = row.find_elements(By.XPATH, columns_xpath)\n",
    "        row_data = [column.text.strip() for column in columns]\n",
    "        # row_data = [column.text for column in columns]\n",
    "        if len(row_data) <1:\n",
    "            continue\n",
    "        else:\n",
    "            table_data.append(row_data)\n",
    "    print(table_data)\n",
    "    for i in range(len(table_data)):\n",
    "        row = [\n",
    "            event_id,\n",
    "            episode,\n",
    "            *table_data[i][:4] \n",
    "        ]\n",
    "        table_9_df.append(row)\n",
    "\n",
    "    for row in table_9_df:\n",
    "        print(row)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    print(f\"Table with the provided XPath '{table_xpath}' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# destination_folder = 'D:\\Web Scraping\\Web-Scraping\\CSV\\Wildfires\\\\'\n",
    "# i=8\n",
    "# col = eval(f\"table_{i}_headers\")\n",
    "# tbl = eval(f'table_{i}_df')\n",
    "# df = pd.DataFrame(tbl,col)\n",
    "# df.head()\n",
    "# csv_file_path = destination_folder+f'{i}.csv'\n",
    "# # Check if the file exists\n",
    "# file_exists = os.path.exists(csv_file_path)\n",
    "#     # Append to the file\n",
    "\n",
    "# # Write or append to the CSV file\n",
    "# # df.to_csv(csv_file_path, mode= 'w', header= True, index=False)\n",
    "# df.to_csv(csv_file_path, mode='a' if file_exists else 'w', header=not file_exists, index=False)\n",
    "# print(f\"Data {'appended to' if file_exists else 'written to'} {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df =pd.DataFrame([['1004452', '10', 'ULCHIN', 'REPUBLIC OF KOREA', '6', '8 km']],columns=['Event_id', 'Episode', 'Name', 'Country', 'Reactor', 'Distance'])\n",
    "# csv_file_path = destination_folder+f'{i}.csv'\n",
    "# # Check if the file exists\n",
    "# file_exists = os.path.exists(csv_file_path)\n",
    "#     # Append to the file\n",
    "\n",
    "# # Write or append to the CSV file\n",
    "# # df.to_csv(csv_file_path, mode= 'w', header= True, index=False)\n",
    "# df.to_csv(csv_file_path, mode='a' if file_exists else 'w', header=not file_exists, index=False)\n",
    "# print(f\"Data {'appended to' if file_exists else 'written to'} {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate CSV Files\n",
    "# destination_folder = 'D:\\Web Scraping\\Web-Scraping\\CSV\\\\test\\\\'\n",
    "# for i in range(1,10):\n",
    "#     header = eval(f\"table_{i}_headers\")\n",
    "#     tbl = eval(f'table_{i}_df')\n",
    "#     df = pd.DataFrame(tbl,columns=header)\n",
    "#     print(df.head())\n",
    "#     csv_file_path = destination_folder+f'{i}.csv'\n",
    "#     # Check if the file exists\n",
    "#     file_exists = os.path.exists(csv_file_path)\n",
    "#         # Append to the file\n",
    "    \n",
    "#     # Write or append to the CSV file\n",
    "#     # df.to_csv(csv_file_path, mode= 'w', header= True, index=False)\n",
    "#     df.to_csv(csv_file_path, mode='a' if file_exists else 'w', header=not file_exists, index=False)\n",
    "#     print(f\"Data {'appended to' if file_exists else 'written to'} {csv_file_path}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
