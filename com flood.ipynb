{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"â€“disable-extensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earthquake Column headers]\n",
    "table_1_headers = ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
    "table_2_headers = ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
    "table_3_headers = ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
    "table_4_headers = ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
    "table_5_headers = ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
    "\n",
    "\n",
    "\n",
    "# Main function\n",
    "def wildfire_csv(html_file):\n",
    "    # File and event details\n",
    "    file_name = html_file.split('/')[-1].split('.')[0]\n",
    "    event_id, episode, event_type = file_name.split('_')[0:3]\n",
    "    print(event_id, episode, event_type)\n",
    "\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(html_file)\n",
    "\n",
    "\n",
    "    # Define table configurations (XPaths and column limits)\n",
    "    table_configs = [\n",
    "        ('//*[@id=\"alert_summary_left\"]/table/tbody', 6),\n",
    "        ('//th[text()=\\'SENDAI Indicator A\\']/ancestor::table/tbody', 4),\n",
    "        ('//th[text()=\\'SENDAI Indicator B\\']/ancestor::table/tbody', 4),\n",
    "        ('//th[text()=\\'SENDAI Indicator C\\']/ancestor::table/tbody', 4),\n",
    "        ('//th[text()=\\'ID\\']/ancestor::table/tbody', 6)\n",
    "    ]\n",
    "\n",
    "    # Process each table\n",
    "    tables_data = []\n",
    "    for i, (xpath, col_limit) in enumerate(table_configs):\n",
    "        table_data = extract_table_data(driver, event_id, episode, xpath, col_limit)\n",
    "        tables_data.append(table_data)\n",
    "    for row in tables_data:\n",
    "        print(row)\n",
    "    driver.quit()\n",
    "\n",
    "    # Define CSV destination\n",
    "    destination_folder = 'CSV'\n",
    "    absolute_folder_path = Path(destination_folder).resolve()\n",
    "\n",
    "    # Generate CSV files\n",
    "    for i, table_data in enumerate(tables_data,start=1):\n",
    "        csv_file_path = f'{absolute_folder_path}\\{event_type}_{i}.csv'\n",
    "        file_exists = os.path.exists(csv_file_path)\n",
    "        header = eval(f\"table_{i}_headers\")\n",
    "        print(i,header)\n",
    "        print(table_data)\n",
    "        df = pd.DataFrame(table_data,columns=header)\n",
    "        df.head()\n",
    "        df.to_csv(csv_file_path, mode='a' if file_exists else 'w', header=not file_exists, index=False)\n",
    "        print(f\"Data {'appended to' if file_exists else 'written to'} {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract table data based on XPath and the number of columns required\n",
    "def extract_table_data(driver, event_id, episode, xpath, col_limit):\n",
    "    table_data = []\n",
    "    if xpath == '//*[@id=\"alert_summary_left\"]/table/tbody' or xpath == '//*[@id=\"tab_responsive\"]/table/tbody' :\n",
    "        try:\n",
    "            temp_tbl=[]\n",
    "            table = driver.find_element(By.XPATH, xpath)\n",
    "            rows = table.find_elements(By.XPATH, './/tr')\n",
    "            event_summary_text = driver.find_element(By.XPATH, '//*[@class=\"p_summary\"][1]').text\n",
    "            for row in rows:\n",
    "                columns = row.find_elements(By.XPATH, './/td')\n",
    "                row_data = [column.text for column in columns]\n",
    "                if len(row_data)>=1:\n",
    "                    temp_tbl.append(row_data)\n",
    "            table_data = [[event_id, episode,*[temp_tbl[i][1] for i in range(1,col_limit)]\n",
    "                        ,event_summary_text]]\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Event summary not founds or table with XPath '{xpath}' not found.\")\n",
    "        return table_data\n",
    "    else:\n",
    "        try:\n",
    "            table = driver.find_element(By.XPATH, xpath)\n",
    "            rows = table.find_elements(By.XPATH, './/tr')\n",
    "            for row in rows:\n",
    "                columns = row.find_elements(By.XPATH, './/td' if col_limit else './/th | .//td')\n",
    "                row_data = []\n",
    "                for col in columns:\n",
    "                    cell_text = col.text.strip()\n",
    "\n",
    "                    # If the cell is empty, look for an image\n",
    "                    if not cell_text:\n",
    "                        img_element = col.find_element(By.TAG_NAME, 'img') if col.find_elements(By.TAG_NAME, 'img') else None\n",
    "                        if img_element:\n",
    "                            # Try to get the title attribute\n",
    "                            image_title = img_element.get_attribute('title')\n",
    "                            if image_title:\n",
    "                                row_data.append(image_title)  # Add the image title if present\n",
    "                            else:\n",
    "                                # Try to get the alt attribute if title is absent\n",
    "                                alt_text = img_element.get_attribute('alt')\n",
    "                                if alt_text:\n",
    "                                    row_data.append(alt_text)  # Add the alt text if present\n",
    "                                else:\n",
    "                                    # If no title or alt, extract from the image URL\n",
    "                                    image_url = img_element.get_attribute('src')\n",
    "                                    image_code = image_url.split('/')[-1].split('.')[0]  # Extract \"8p\" from URL\n",
    "                                    row_data.append(image_code)  # Add the extracted part from the URL\n",
    "                        else:\n",
    "                            row_data.append(\"\")  # Leave it blank if no image is founD\n",
    "                    else:\n",
    "                        # If the cell contains text, just add it\n",
    "                        row_data.append(cell_text)\n",
    "\n",
    "                if len(row_data) >= 1:\n",
    "                    table_data.append([event_id, episode] + row_data[:col_limit if col_limit else len(row_data)])\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Table with XPath '{xpath}' not found.\")\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_filenames(folder_path):\n",
    "    try:\n",
    "        # Get a list of all files in the specified folder\n",
    "        filenames = os.listdir(folder_path)\n",
    "        \n",
    "        return filenames\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def main():\n",
    "    folder_path = \"latest_htmls/Floods\"\n",
    "    absolute_folder_path = Path(folder_path).resolve()\n",
    "    filenames = list_filenames(absolute_folder_path)\n",
    "\n",
    "    for file in filenames:\n",
    "        absolute_file_path = absolute_folder_path / file\n",
    "        wildfire_csv(f\"file:///{absolute_file_path.as_posix()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100902 1 Floods\n",
      "[['1100902', '1', '10', '4350061', 'Jharkhand, West Bengal, Odisha, Tamil Nadu, Bhola District', 'Bangladesh, India', '24 May - 31 May', 'Flood Bangladesh, India is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[['1100902', '1', 'death', '2', 'India', 'Odisha'], ['1100902', '1', 'death', '8', 'India', 'Tamil Nadu']]\n",
      "[['1100902', '1', 'displaced', '10773', 'India', 'Jharkhand'], ['1100902', '1', 'displaced', '809830', 'India', 'West Bengal'], ['1100902', '1', 'displaced', '593656', 'India', 'Odisha'], ['1100902', '1', 'displaced', '7476', 'India', 'Tamil Nadu'], ['1100902', '1', 'displaced', '703058', 'India', 'Odisha'], ['1100902', '1', 'displaced', '17165', 'India', 'Jharkhand'], ['1100902', '1', 'displaced', '702986', 'India', 'Odisha'], ['1100902', '1', 'displaced', '1504506', 'India', 'West Bengal'], ['1100902', '1', 'displaced', '611', 'India', 'Tamil Nadu']]\n",
      "[['1100902', '1', 'houses damaged', '4500', 'Bangladesh', 'Bhola District'], ['1100902', '1', 'houses destroyed', '993', 'India', 'Odisha'], ['1100902', '1', 'houses destroyed', '142', 'India', 'Odisha']]\n",
      "[['1100902', '1', '1', 'FL', '18 deaths and 5854567 displaced', '24 May 2021', '31 May 2021', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1100902', '1', '10', '4350061', 'Jharkhand, West Bengal, Odisha, Tamil Nadu, Bhola District', 'Bangladesh, India', '24 May - 31 May', 'Flood Bangladesh, India is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data written to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100902', '1', 'death', '2', 'India', 'Odisha'], ['1100902', '1', 'death', '8', 'India', 'Tamil Nadu']]\n",
      "Data written to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100902', '1', 'displaced', '10773', 'India', 'Jharkhand'], ['1100902', '1', 'displaced', '809830', 'India', 'West Bengal'], ['1100902', '1', 'displaced', '593656', 'India', 'Odisha'], ['1100902', '1', 'displaced', '7476', 'India', 'Tamil Nadu'], ['1100902', '1', 'displaced', '703058', 'India', 'Odisha'], ['1100902', '1', 'displaced', '17165', 'India', 'Jharkhand'], ['1100902', '1', 'displaced', '702986', 'India', 'Odisha'], ['1100902', '1', 'displaced', '1504506', 'India', 'West Bengal'], ['1100902', '1', 'displaced', '611', 'India', 'Tamil Nadu']]\n",
      "Data written to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100902', '1', 'houses damaged', '4500', 'Bangladesh', 'Bhola District'], ['1100902', '1', 'houses destroyed', '993', 'India', 'Odisha'], ['1100902', '1', 'houses destroyed', '142', 'India', 'Odisha']]\n",
      "Data written to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1100902', '1', '1', 'FL', '18 deaths and 5854567 displaced', '24 May 2021', '31 May 2021', 'GLOFAS']]\n",
      "Data written to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n",
      "1100932 7 Floods\n",
      "[['1100932', '7', '110', '2518000', 'Taiyuan', 'China', '20 Jun - 30 Jul', 'Flood China is expected to have a low humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[['1100932', '7', 'death', '12', 'China', 'Zhengzhou'], ['1100932', '7', 'death', '33', 'China', 'Henan'], ['1100932', '7', 'death', '63', 'China', 'Henan'], ['1100932', '7', 'death', '2', 'China', 'Taiyuan']]\n",
      "[['1100932', '7', 'affected', '42000', 'China', 'Heilongjiang'], ['1100932', '7', 'affected', '47000', 'China', 'Hulunbuir'], ['1100932', '7', 'affected', '1080000', 'China', 'Jiangxi'], ['1100932', '7', 'affected', '589400', 'China', 'Sichuan'], ['1100932', '7', 'affected', '2000000', 'China', 'Xinxiang'], ['1100932', '7', 'displaced', '1500000', 'China', 'Zhejiang'], ['1100932', '7', 'displaced', '360000', 'China', 'Shanghai'], ['1100932', '7', 'displaced', '19000', 'China', 'Heilongjiang'], ['1100932', '7', 'displaced', '376000', 'China', 'Henan'], ['1100932', '7', 'displaced', '100000', 'China', 'Henan'], ['1100932', '7', 'displaced', '63000', 'China', 'Jiangxi'], ['1100932', '7', 'displaced', '100000', 'China', 'Sichuan'], ['1100932', '7', 'rescued', '50', 'China', 'Dalian'], ['1100932', '7', 'rescued', '50', 'China', 'Du an Yao Autonomous County']]\n",
      "[['1100932', '7', 'houses damaged', '219', 'China', 'Jiangxi'], ['1100932', '7', 'houses destroyed', '156', 'China', 'Jiangxi']]\n",
      "[['1100932', '7', '1', 'FL', '0 deaths and 19000 displaced', '20 Jun 2021', '22 Jun 2021', 'GLOFAS'], ['1100932', '7', '2', 'FL', '0 deaths', '28 Jun 2021', '30 Jun 2021', 'GLOFAS'], ['1100932', '7', '3', 'FL', '0 deaths and 63000 displaced', '28 Jun 2021', '04 Jul 2021', 'GLOFAS'], ['1100932', '7', '4', 'FL', '0 deaths and 100000 displaced', '09 Jul 2021', '15 Jul 2021', 'GLOFAS'], ['1100932', '7', '5', 'FL', '108 deaths and 852000 displaced', '17 Jul 2021', '19 Jul 2021', 'GLOFAS'], ['1100932', '7', '6', 'FL', '0 deaths and 1860000 displaced', '26 Jul 2021', '28 Jul 2021', 'GLOFAS'], ['1100932', '7', '7', 'FL', '2 deaths', '29 Jul 2021', '30 Jul 2021', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1100932', '7', '110', '2518000', 'Taiyuan', 'China', '20 Jun - 30 Jul', 'Flood China is expected to have a low humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100932', '7', 'death', '12', 'China', 'Zhengzhou'], ['1100932', '7', 'death', '33', 'China', 'Henan'], ['1100932', '7', 'death', '63', 'China', 'Henan'], ['1100932', '7', 'death', '2', 'China', 'Taiyuan']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100932', '7', 'affected', '42000', 'China', 'Heilongjiang'], ['1100932', '7', 'affected', '47000', 'China', 'Hulunbuir'], ['1100932', '7', 'affected', '1080000', 'China', 'Jiangxi'], ['1100932', '7', 'affected', '589400', 'China', 'Sichuan'], ['1100932', '7', 'affected', '2000000', 'China', 'Xinxiang'], ['1100932', '7', 'displaced', '1500000', 'China', 'Zhejiang'], ['1100932', '7', 'displaced', '360000', 'China', 'Shanghai'], ['1100932', '7', 'displaced', '19000', 'China', 'Heilongjiang'], ['1100932', '7', 'displaced', '376000', 'China', 'Henan'], ['1100932', '7', 'displaced', '100000', 'China', 'Henan'], ['1100932', '7', 'displaced', '63000', 'China', 'Jiangxi'], ['1100932', '7', 'displaced', '100000', 'China', 'Sichuan'], ['1100932', '7', 'rescued', '50', 'China', 'Dalian'], ['1100932', '7', 'rescued', '50', 'China', 'Du an Yao Autonomous County']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100932', '7', 'houses damaged', '219', 'China', 'Jiangxi'], ['1100932', '7', 'houses destroyed', '156', 'China', 'Jiangxi']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1100932', '7', '1', 'FL', '0 deaths and 19000 displaced', '20 Jun 2021', '22 Jun 2021', 'GLOFAS'], ['1100932', '7', '2', 'FL', '0 deaths', '28 Jun 2021', '30 Jun 2021', 'GLOFAS'], ['1100932', '7', '3', 'FL', '0 deaths and 63000 displaced', '28 Jun 2021', '04 Jul 2021', 'GLOFAS'], ['1100932', '7', '4', 'FL', '0 deaths and 100000 displaced', '09 Jul 2021', '15 Jul 2021', 'GLOFAS'], ['1100932', '7', '5', 'FL', '108 deaths and 852000 displaced', '17 Jul 2021', '19 Jul 2021', 'GLOFAS'], ['1100932', '7', '6', 'FL', '0 deaths and 1860000 displaced', '26 Jul 2021', '28 Jul 2021', 'GLOFAS'], ['1100932', '7', '7', 'FL', '2 deaths', '29 Jul 2021', '30 Jul 2021', 'GLOFAS']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n",
      "1100977 26 Floods\n",
      "[['1100977', '26', '415', '1358720', 'Shimla', 'India', '24 Jul - 01 Oct', 'Flood India is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[['1100977', '26', 'death', '14', 'India', 'Vikhroli'], ['1100977', '26', 'death', '6', 'India', 'Chembur'], ['1100977', '26', 'death', '5', 'India', 'Thane'], ['1100977', '26', 'death', '6', 'India', 'Kangra district'], ['1100977', '26', 'death', '9', 'India', 'Karnataka'], ['1100977', '26', 'death', '7', 'India', 'Govandi'], ['1100977', '26', 'death', '5', 'India', 'Mahad'], ['1100977', '26', 'death', '192', 'India', 'Maharashtra'], ['1100977', '26', 'death', '14', 'India', 'West Bengal'], ['1100977', '26', 'death', '2', 'India', 'South Sikkim district'], ['1100977', '26', 'death', '9', 'India', 'Kinnaur'], ['1100977', '26', 'death', '7', 'India', 'Lahaul And Spiti'], ['1100977', '26', 'death', '3', 'India', 'Madhya Pradesh'], ['1100977', '26', 'death', '24', 'India', 'Madhya Pradesh'], ['1100977', '26', 'death', '7', 'India', 'Bundi'], ['1100977', '26', 'death', '12', 'India', 'Bihar'], ['1100977', '26', 'death', '5', 'China', 'Sarang'], ['1100977', '26', 'death', '2', 'India', 'Kothagudem'], ['1100977', '26', 'death', '1', 'India', 'Warangal'], ['1100977', '26', 'death', '2', 'India', 'West Godavari'], ['1100977', '26', 'death', '10', 'India', 'West Bengal'], ['1100977', '26', 'death', '52', 'India', 'Uttar Pradesh'], ['1100977', '26', 'death', '1', 'India', 'Vikarabad'], ['1100977', '26', 'death', '11', 'India', 'West Bengal'], ['1100977', '26', 'death', '7', 'India', 'Kishtwar District'], ['1100977', '26', 'death', '1', 'India', 'Chalisgaon'], ['1100977', '26', 'death', '1', 'India', 'Belonia'], ['1100977', '26', 'missing', '2', 'India', 'Gairsain'], ['1100977', '26', 'missing', '19', 'India', 'Kishtwar District'], ['1100977', '26', 'missing', '15', 'India', 'Mokhada']]\n",
      "[['1100977', '26', 'affected', '2', 'India', 'Goa'], ['1100977', '26', 'affected', '400', 'India', 'Kandivali West'], ['1100977', '26', 'affected', '252000', 'India', 'Bihar'], ['1100977', '26', 'affected', '2700000', 'India', 'Bihar'], ['1100977', '26', 'affected', '104704', 'India', 'Uttar Pradesh'], ['1100977', '26', 'affected', '22022', 'India', 'Assam'], ['1100977', '26', 'affected', '1200000', 'India', 'West Bengal'], ['1100977', '26', 'affected', '90000', 'India', 'Uttar Pradesh'], ['1100977', '26', 'affected', '2600000', 'India', 'West Bengal'], ['1100977', '26', 'displaced', '500000', 'India', 'West Bengal'], ['1100977', '26', 'displaced', '1200', 'India', 'Uttar Pradesh'], ['1100977', '26', 'displaced', '22468', 'India', 'Odisha'], ['1100977', '26', 'displaced', '512', 'India', 'Srikakulam'], ['1100977', '26', 'displaced', '3940', 'India', 'Srikakulam'], ['1100977', '26', 'displaced', '46075', 'India', 'Odisha'], ['1100977', '26', 'displaced', '1300', 'India', 'West Bengal'], ['1100977', '26', 'displaced', '5000', 'India', 'Krishna district'], ['1100977', '26', 'displaced', '770', 'India', 'Assam'], ['1100977', '26', 'displaced', '6237', 'India', 'Uttar Pradesh'], ['1100977', '26', 'displaced', '85000', 'India', 'Bihar'], ['1100977', '26', 'displaced', '400', 'India', 'Goa'], ['1100977', '26', 'displaced', '29280', 'India', 'Madhya Pradesh'], ['1100977', '26', 'displaced', '31360', 'India', 'Karnataka'], ['1100977', '26', 'displaced', '375178', 'India', 'Maharashtra'], ['1100977', '26', 'displaced', '250000', 'India', 'West Bengal'], ['1100977', '26', 'injured', '17', 'India', 'Kishtwar District'], ['1100977', '26', 'injured', '2', 'India', 'Belonia'], ['1100977', '26', 'injured', '1', 'India', 'Chamoli'], ['1100977', '26', 'rescued', '5950', 'India', 'Madhya Pradesh'], ['1100977', '26', 'rescued', '8832', 'India', 'Madhya Pradesh'], ['1100977', '26', 'rescued', '40', 'India', 'Itawa'], ['1100977', '26', 'rescued', '9', 'India', 'Baran']]\n",
      "[['1100977', '26', 'houses', '272', 'India', 'Uttar Pradesh'], ['1100977', '26', 'houses', '15', 'India', 'Uttar Pradesh'], ['1100977', '26', 'houses', '42', 'India', 'Andhra Pradesh'], ['1100977', '26', 'houses damaged', '3', 'India', 'Shimla'], ['1100977', '26', 'houses destroyed', '19', 'India', 'Kishtwar District'], ['1100977', '26', 'houses destroyed', '6', 'India', 'Chamoli'], ['1100977', '26', 'houses destroyed', '1', 'India', 'Thane'], ['1100977', '26', 'houses destroyed', '28', 'India', 'Himachal Pradesh'], ['1100977', '26', 'houses destroyed', '6', 'India', 'Thane district']]\n",
      "[['1100977', '26', '1', 'FL', '25 deaths', '17 Jul 2021', '19 Jul 2021', 'GLOFAS'], ['1100977', '26', '2', 'FL', '6 deaths', '11 Jul 2021', '14 Jul 2021', 'GLOFAS'], ['1100977', '26', '3', 'FL', '0 deaths and 400 displaced', '22 Jul 2021', '26 Jul 2021', 'GLOFAS'], ['1100977', '26', '4', 'FL', '9 deaths and 31360 displaced', '22 Jul 2021', '24 Jul 2021', 'GLOFAS'], ['1100977', '26', '5', 'FL', '204 deaths and 375178 displaced', '22 Jul 2021', '24 Jul 2021', 'GLOFAS'], ['1100977', '26', '6', 'FL', '7 deaths', '28 Jul 2021', '02 Aug 2021', 'GLOFAS'], ['1100977', '26', '7', 'FL', '14 deaths and 250000 displaced', '29 Jul 2021', '31 Jul 2021', 'GLOFAS'], ['1100977', '26', '8', 'FL', '2 deaths', '29 Jul 2021', '31 Jul 2021', 'GLOFAS'], ['1100977', '26', '9', 'FL', '16 deaths', '25 Jul 2021', '30 Jul 2021', 'GLOFAS'], ['1100977', '26', '10', 'FL', '27 deaths and 29280 displaced', '01 Aug 2021', '03 Aug 2021', 'GLOFAS'], ['1100977', '26', '11', 'FL', '0 deaths', '07 Aug 2021', '09 Aug 2021', 'GLOFAS'], ['1100977', '26', '12', 'FL', '7 deaths', '03 Aug 2021', '05 Aug 2021', 'GLOFAS'], ['1100977', '26', '13', 'FL', '12 deaths and 85000 displaced', '05 Aug 2021', '07 Aug 2021', 'GLOFAS'], ['1100977', '26', '14', 'FL', '0 deaths and 6237 displaced', '06 Aug 2021', '08 Aug 2021', 'GLOFAS'], ['1100977', '26', '15', 'FL', '0 deaths and 5000 displaced', '04 Aug 2021', '06 Aug 2021', 'GLOFAS'], ['1100977', '26', '16', 'FL', '0 deaths and 770 displaced', '16 Aug 2021', '18 Aug 2021', 'GLOFAS'], ['1100977', '26', '17', 'FL', '1 deaths', '', '', 'GLOFAS'], ['1100977', '26', '18', 'FL', '1 deaths', '30 Aug 2021', '01 Sep 2021', 'GLOFAS'], ['1100977', '26', '19', 'FL', '5 deaths', '29 Aug 2021', '31 Aug 2021', 'GLOFAS'], ['1100977', '26', '20', 'FL', '5 deaths', '06 Sep 2021', '08 Sep 2021', 'GLOFAS'], ['1100977', '26', '21', 'FL', '10 deaths and 1300 displaced', '14 Sep 2021', '16 Sep 2021', 'GLOFAS'], ['1100977', '26', '22', 'FL', '52 deaths and 1200 displaced', '15 Sep 2021', '17 Sep 2021', 'GLOFAS'], ['1100977', '26', '23', 'FL', '0 deaths', '', '', 'GLOFAS'], ['1100977', '26', '24', 'FL', '1 deaths and 72995 displaced', '26 Sep 2021', '28 Sep 2021', 'GLOFAS'], ['1100977', '26', '25', 'FL', '11 deaths and 500000 displaced', '30 Sep 2021', '02 Oct 2021', 'GLOFAS'], ['1100977', '26', '26', 'FL', '0 deaths', '30 Sep 2021', '01 Oct 2021', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1100977', '26', '415', '1358720', 'Shimla', 'India', '24 Jul - 01 Oct', 'Flood India is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100977', '26', 'death', '14', 'India', 'Vikhroli'], ['1100977', '26', 'death', '6', 'India', 'Chembur'], ['1100977', '26', 'death', '5', 'India', 'Thane'], ['1100977', '26', 'death', '6', 'India', 'Kangra district'], ['1100977', '26', 'death', '9', 'India', 'Karnataka'], ['1100977', '26', 'death', '7', 'India', 'Govandi'], ['1100977', '26', 'death', '5', 'India', 'Mahad'], ['1100977', '26', 'death', '192', 'India', 'Maharashtra'], ['1100977', '26', 'death', '14', 'India', 'West Bengal'], ['1100977', '26', 'death', '2', 'India', 'South Sikkim district'], ['1100977', '26', 'death', '9', 'India', 'Kinnaur'], ['1100977', '26', 'death', '7', 'India', 'Lahaul And Spiti'], ['1100977', '26', 'death', '3', 'India', 'Madhya Pradesh'], ['1100977', '26', 'death', '24', 'India', 'Madhya Pradesh'], ['1100977', '26', 'death', '7', 'India', 'Bundi'], ['1100977', '26', 'death', '12', 'India', 'Bihar'], ['1100977', '26', 'death', '5', 'China', 'Sarang'], ['1100977', '26', 'death', '2', 'India', 'Kothagudem'], ['1100977', '26', 'death', '1', 'India', 'Warangal'], ['1100977', '26', 'death', '2', 'India', 'West Godavari'], ['1100977', '26', 'death', '10', 'India', 'West Bengal'], ['1100977', '26', 'death', '52', 'India', 'Uttar Pradesh'], ['1100977', '26', 'death', '1', 'India', 'Vikarabad'], ['1100977', '26', 'death', '11', 'India', 'West Bengal'], ['1100977', '26', 'death', '7', 'India', 'Kishtwar District'], ['1100977', '26', 'death', '1', 'India', 'Chalisgaon'], ['1100977', '26', 'death', '1', 'India', 'Belonia'], ['1100977', '26', 'missing', '2', 'India', 'Gairsain'], ['1100977', '26', 'missing', '19', 'India', 'Kishtwar District'], ['1100977', '26', 'missing', '15', 'India', 'Mokhada']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100977', '26', 'affected', '2', 'India', 'Goa'], ['1100977', '26', 'affected', '400', 'India', 'Kandivali West'], ['1100977', '26', 'affected', '252000', 'India', 'Bihar'], ['1100977', '26', 'affected', '2700000', 'India', 'Bihar'], ['1100977', '26', 'affected', '104704', 'India', 'Uttar Pradesh'], ['1100977', '26', 'affected', '22022', 'India', 'Assam'], ['1100977', '26', 'affected', '1200000', 'India', 'West Bengal'], ['1100977', '26', 'affected', '90000', 'India', 'Uttar Pradesh'], ['1100977', '26', 'affected', '2600000', 'India', 'West Bengal'], ['1100977', '26', 'displaced', '500000', 'India', 'West Bengal'], ['1100977', '26', 'displaced', '1200', 'India', 'Uttar Pradesh'], ['1100977', '26', 'displaced', '22468', 'India', 'Odisha'], ['1100977', '26', 'displaced', '512', 'India', 'Srikakulam'], ['1100977', '26', 'displaced', '3940', 'India', 'Srikakulam'], ['1100977', '26', 'displaced', '46075', 'India', 'Odisha'], ['1100977', '26', 'displaced', '1300', 'India', 'West Bengal'], ['1100977', '26', 'displaced', '5000', 'India', 'Krishna district'], ['1100977', '26', 'displaced', '770', 'India', 'Assam'], ['1100977', '26', 'displaced', '6237', 'India', 'Uttar Pradesh'], ['1100977', '26', 'displaced', '85000', 'India', 'Bihar'], ['1100977', '26', 'displaced', '400', 'India', 'Goa'], ['1100977', '26', 'displaced', '29280', 'India', 'Madhya Pradesh'], ['1100977', '26', 'displaced', '31360', 'India', 'Karnataka'], ['1100977', '26', 'displaced', '375178', 'India', 'Maharashtra'], ['1100977', '26', 'displaced', '250000', 'India', 'West Bengal'], ['1100977', '26', 'injured', '17', 'India', 'Kishtwar District'], ['1100977', '26', 'injured', '2', 'India', 'Belonia'], ['1100977', '26', 'injured', '1', 'India', 'Chamoli'], ['1100977', '26', 'rescued', '5950', 'India', 'Madhya Pradesh'], ['1100977', '26', 'rescued', '8832', 'India', 'Madhya Pradesh'], ['1100977', '26', 'rescued', '40', 'India', 'Itawa'], ['1100977', '26', 'rescued', '9', 'India', 'Baran']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1100977', '26', 'houses', '272', 'India', 'Uttar Pradesh'], ['1100977', '26', 'houses', '15', 'India', 'Uttar Pradesh'], ['1100977', '26', 'houses', '42', 'India', 'Andhra Pradesh'], ['1100977', '26', 'houses damaged', '3', 'India', 'Shimla'], ['1100977', '26', 'houses destroyed', '19', 'India', 'Kishtwar District'], ['1100977', '26', 'houses destroyed', '6', 'India', 'Chamoli'], ['1100977', '26', 'houses destroyed', '1', 'India', 'Thane'], ['1100977', '26', 'houses destroyed', '28', 'India', 'Himachal Pradesh'], ['1100977', '26', 'houses destroyed', '6', 'India', 'Thane district']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1100977', '26', '1', 'FL', '25 deaths', '17 Jul 2021', '19 Jul 2021', 'GLOFAS'], ['1100977', '26', '2', 'FL', '6 deaths', '11 Jul 2021', '14 Jul 2021', 'GLOFAS'], ['1100977', '26', '3', 'FL', '0 deaths and 400 displaced', '22 Jul 2021', '26 Jul 2021', 'GLOFAS'], ['1100977', '26', '4', 'FL', '9 deaths and 31360 displaced', '22 Jul 2021', '24 Jul 2021', 'GLOFAS'], ['1100977', '26', '5', 'FL', '204 deaths and 375178 displaced', '22 Jul 2021', '24 Jul 2021', 'GLOFAS'], ['1100977', '26', '6', 'FL', '7 deaths', '28 Jul 2021', '02 Aug 2021', 'GLOFAS'], ['1100977', '26', '7', 'FL', '14 deaths and 250000 displaced', '29 Jul 2021', '31 Jul 2021', 'GLOFAS'], ['1100977', '26', '8', 'FL', '2 deaths', '29 Jul 2021', '31 Jul 2021', 'GLOFAS'], ['1100977', '26', '9', 'FL', '16 deaths', '25 Jul 2021', '30 Jul 2021', 'GLOFAS'], ['1100977', '26', '10', 'FL', '27 deaths and 29280 displaced', '01 Aug 2021', '03 Aug 2021', 'GLOFAS'], ['1100977', '26', '11', 'FL', '0 deaths', '07 Aug 2021', '09 Aug 2021', 'GLOFAS'], ['1100977', '26', '12', 'FL', '7 deaths', '03 Aug 2021', '05 Aug 2021', 'GLOFAS'], ['1100977', '26', '13', 'FL', '12 deaths and 85000 displaced', '05 Aug 2021', '07 Aug 2021', 'GLOFAS'], ['1100977', '26', '14', 'FL', '0 deaths and 6237 displaced', '06 Aug 2021', '08 Aug 2021', 'GLOFAS'], ['1100977', '26', '15', 'FL', '0 deaths and 5000 displaced', '04 Aug 2021', '06 Aug 2021', 'GLOFAS'], ['1100977', '26', '16', 'FL', '0 deaths and 770 displaced', '16 Aug 2021', '18 Aug 2021', 'GLOFAS'], ['1100977', '26', '17', 'FL', '1 deaths', '', '', 'GLOFAS'], ['1100977', '26', '18', 'FL', '1 deaths', '30 Aug 2021', '01 Sep 2021', 'GLOFAS'], ['1100977', '26', '19', 'FL', '5 deaths', '29 Aug 2021', '31 Aug 2021', 'GLOFAS'], ['1100977', '26', '20', 'FL', '5 deaths', '06 Sep 2021', '08 Sep 2021', 'GLOFAS'], ['1100977', '26', '21', 'FL', '10 deaths and 1300 displaced', '14 Sep 2021', '16 Sep 2021', 'GLOFAS'], ['1100977', '26', '22', 'FL', '52 deaths and 1200 displaced', '15 Sep 2021', '17 Sep 2021', 'GLOFAS'], ['1100977', '26', '23', 'FL', '0 deaths', '', '', 'GLOFAS'], ['1100977', '26', '24', 'FL', '1 deaths and 72995 displaced', '26 Sep 2021', '28 Sep 2021', 'GLOFAS'], ['1100977', '26', '25', 'FL', '11 deaths and 500000 displaced', '30 Sep 2021', '02 Oct 2021', 'GLOFAS'], ['1100977', '26', '26', 'FL', '0 deaths', '30 Sep 2021', '01 Oct 2021', 'GLOFAS']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n",
      "1101522 1 Floods\n",
      "Table with XPath '//th[text()='SENDAI Indicator C']/ancestor::table/tbody' not found.\n",
      "[['1101522', '1', '1061', '215997', 'Gilgit-Baltistan, Balochistan, Azad Kashmir, Khyber Pakhtunkhwa, Punjab, Gilgit-Baltistan, Sindh', 'Pakistan', '14 Jun - 31 Aug', 'Flood Pakistan is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[['1101522', '1', 'death', '1061', 'Pakistan', 'Gilgit-Baltistan, Azad Kashmir, Punjab, Khyber Pakhtunkhwa, Sindh, Balochistan']]\n",
      "[['1101522', '1', 'displaced', '215997', 'Pakistan', 'Gilgit-Baltistan, Balochistan, Azad Kashmir, Khyber Pakhtunkhwa, Punjab'], ['1101522', '1', 'injured', '1575', 'Pakistan', 'Punjab, Gilgit-Baltistan, Azad Kashmir, Khyber Pakhtunkhwa, Sindh, Balochistan']]\n",
      "[]\n",
      "[['1101522', '1', '1', 'FL', '1061 deaths and 215997 displaced', '14 Jun 2022', '29 Aug 2022', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1101522', '1', '1061', '215997', 'Gilgit-Baltistan, Balochistan, Azad Kashmir, Khyber Pakhtunkhwa, Punjab, Gilgit-Baltistan, Sindh', 'Pakistan', '14 Jun - 31 Aug', 'Flood Pakistan is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1101522', '1', 'death', '1061', 'Pakistan', 'Gilgit-Baltistan, Azad Kashmir, Punjab, Khyber Pakhtunkhwa, Sindh, Balochistan']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1101522', '1', 'displaced', '215997', 'Pakistan', 'Gilgit-Baltistan, Balochistan, Azad Kashmir, Khyber Pakhtunkhwa, Punjab'], ['1101522', '1', 'injured', '1575', 'Pakistan', 'Punjab, Gilgit-Baltistan, Azad Kashmir, Khyber Pakhtunkhwa, Sindh, Balochistan']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1101522', '1', '1', 'FL', '1061 deaths and 215997 displaced', '14 Jun 2022', '29 Aug 2022', 'GLOFAS']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n",
      "1101659 5 Floods\n",
      "[['1101659', '5', '605', '1306000', 'Bayelsa State, Delta State, Anambra State, Abuja, Cross River State, Rivers State, Bayelsa State', 'Nigeria', '10 Sep - 26 Oct', 'Flood Nigeria is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[['1101659', '5', 'death', '2', 'Nigeria', 'Lagos'], ['1101659', '5', 'death', '603', 'Nigeria', '-']]\n",
      "[['1101659', '5', 'affected', '35200', 'Nigeria', 'Uzo-Uwani'], ['1101659', '5', 'affected', '2504000', 'Nigeria', 'Bayelsa State, Delta State, Anambra State, Abuja, Cross River State, Rivers State'], ['1101659', '5', 'affected', '1', 'Nigeria', 'Mariga'], ['1101659', '5', 'displaced', '3000', 'Nigeria', 'Lokoja'], ['1101659', '5', 'displaced', '1303000', 'Nigeria', 'Cross River State, Delta State, Rivers State, Bayelsa State, Abuja, Anambra State'], ['1101659', '5', 'injured', '2400', 'Nigeria', 'Delta State, Abuja, Anambra State, Cross River State, Rivers State, Bayelsa State'], ['1101659', '5', 'rescued', '9', 'Nigeria', 'Maryland']]\n",
      "[['1101659', '5', 'agriculture', '53800', 'Nigeria', 'Uzo-Uwani'], ['1101659', '5', 'houses', '1', 'Nigeria', 'Maryland'], ['1101659', '5', 'houses damaged', '500', 'Nigeria', 'Lokoja'], ['1101659', '5', 'houses damaged', '-', 'Nigeria', 'Uzo-Uwani']]\n",
      "[['1101659', '5', '1', 'FL', '2 deaths', '10 Sep 2022', '12 Sep 2022', 'GLOFAS'], ['1101659', '5', '2', 'FL', '0 deaths', '15 Sep 2022', '17 Sep 2022', 'GLOFAS'], ['1101659', '5', '3', 'FL', '0 deaths and 3000 displaced', '23 Sep 2022', '25 Sep 2022', 'GLOFAS'], ['1101659', '5', '4', 'FL', '0 deaths', '01 Oct 2022', '03 Oct 2022', 'GLOFAS'], ['1101659', '5', '5', 'FL', '603 deaths and 1303000 displaced', '01 Oct 2022', '26 Oct 2022', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1101659', '5', '605', '1306000', 'Bayelsa State, Delta State, Anambra State, Abuja, Cross River State, Rivers State, Bayelsa State', 'Nigeria', '10 Sep - 26 Oct', 'Flood Nigeria is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1101659', '5', 'death', '2', 'Nigeria', 'Lagos'], ['1101659', '5', 'death', '603', 'Nigeria', '-']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1101659', '5', 'affected', '35200', 'Nigeria', 'Uzo-Uwani'], ['1101659', '5', 'affected', '2504000', 'Nigeria', 'Bayelsa State, Delta State, Anambra State, Abuja, Cross River State, Rivers State'], ['1101659', '5', 'affected', '1', 'Nigeria', 'Mariga'], ['1101659', '5', 'displaced', '3000', 'Nigeria', 'Lokoja'], ['1101659', '5', 'displaced', '1303000', 'Nigeria', 'Cross River State, Delta State, Rivers State, Bayelsa State, Abuja, Anambra State'], ['1101659', '5', 'injured', '2400', 'Nigeria', 'Delta State, Abuja, Anambra State, Cross River State, Rivers State, Bayelsa State'], ['1101659', '5', 'rescued', '9', 'Nigeria', 'Maryland']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1101659', '5', 'agriculture', '53800', 'Nigeria', 'Uzo-Uwani'], ['1101659', '5', 'houses', '1', 'Nigeria', 'Maryland'], ['1101659', '5', 'houses damaged', '500', 'Nigeria', 'Lokoja'], ['1101659', '5', 'houses damaged', '-', 'Nigeria', 'Uzo-Uwani']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1101659', '5', '1', 'FL', '2 deaths', '10 Sep 2022', '12 Sep 2022', 'GLOFAS'], ['1101659', '5', '2', 'FL', '0 deaths', '15 Sep 2022', '17 Sep 2022', 'GLOFAS'], ['1101659', '5', '3', 'FL', '0 deaths and 3000 displaced', '23 Sep 2022', '25 Sep 2022', 'GLOFAS'], ['1101659', '5', '4', 'FL', '0 deaths', '01 Oct 2022', '03 Oct 2022', 'GLOFAS'], ['1101659', '5', '5', 'FL', '603 deaths and 1303000 displaced', '01 Oct 2022', '26 Oct 2022', 'GLOFAS']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n",
      "1101664 1 Floods\n",
      "Table with XPath '//th[text()='SENDAI Indicator A']/ancestor::table/tbody' not found.\n",
      "Table with XPath '//th[text()='SENDAI Indicator C']/ancestor::table/tbody' not found.\n",
      "[['1101664', '1', '0', '1233000', 'Shanghai, Zhejiang', 'China, Taiwan', '14 Sep - 16 Sep', 'Flood China, Taiwan is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[]\n",
      "[['1101664', '1', 'displaced', '395000', 'China', 'Shanghai'], ['1101664', '1', 'displaced', '838000', 'China', 'Zhejiang']]\n",
      "[]\n",
      "[['1101664', '1', '1', 'FL', '0 deaths and 1233000 displaced', '14 Sep 2022', '16 Sep 2022', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1101664', '1', '0', '1233000', 'Shanghai, Zhejiang', 'China, Taiwan', '14 Sep - 16 Sep', 'Flood China, Taiwan is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1101664', '1', 'displaced', '395000', 'China', 'Shanghai'], ['1101664', '1', 'displaced', '838000', 'China', 'Zhejiang']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1101664', '1', '1', 'FL', '0 deaths and 1233000 displaced', '14 Sep 2022', '16 Sep 2022', 'GLOFAS']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n",
      "1102000 1 Floods\n",
      "Table with XPath '//th[text()='SENDAI Indicator C']/ancestor::table/tbody' not found.\n",
      "[['1102000', '1', '41', '850000', 'Sittwe Township, Sittwe District, Sittwe Township, Cox s Bazar District', 'Bangladesh, India, Myanmar', '13 May - 15 May', 'This flood is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[['1102000', '1', 'death', '41', 'Myanmar', 'Sittwe Township, Sittwe District']]\n",
      "[['1102000', '1', 'displaced', '100000', 'Myanmar', 'Sittwe Township, Sittwe District'], ['1102000', '1', 'displaced', '750000', 'Bangladesh', 'Cox s Bazar District'], ['1102000', '1', 'injured', '700', 'Myanmar', 'Sittwe District, Sittwe Township']]\n",
      "[]\n",
      "[['1102000', '1', '1', 'FL', '41 deaths and 850000 displaced', '13 May 2023', '15 May 2023', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1102000', '1', '41', '850000', 'Sittwe Township, Sittwe District, Sittwe Township, Cox s Bazar District', 'Bangladesh, India, Myanmar', '13 May - 15 May', 'This flood is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1102000', '1', 'death', '41', 'Myanmar', 'Sittwe Township, Sittwe District']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1102000', '1', 'displaced', '100000', 'Myanmar', 'Sittwe Township, Sittwe District'], ['1102000', '1', 'displaced', '750000', 'Bangladesh', 'Cox s Bazar District'], ['1102000', '1', 'injured', '700', 'Myanmar', 'Sittwe District, Sittwe Township']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1102000', '1', '1', 'FL', '41 deaths and 850000 displaced', '13 May 2023', '15 May 2023', 'GLOFAS']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n",
      "1102204 2 Floods\n",
      "Table with XPath '//th[text()='SENDAI Indicator C']/ancestor::table/tbody' not found.\n",
      "[['1102204', '2', '5300', '33000', 'Darnah, Susah, Derna, Benghazi, Darnah', 'Libya', '08 Sep - 14 Sep', 'This flood is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "[['1102204', '2', 'death', '5300', 'Libya', 'Darnah, Susah, Derna, Benghazi'], ['1102204', '2', 'missing', '10000', 'Libya', 'Susah, Benghazi, Derna, Darnah']]\n",
      "[['1102204', '2', 'displaced', '33000', 'Libya', 'Benghazi, Darnah, Susah, Derna']]\n",
      "[]\n",
      "[['1102204', '2', '1', 'FL', '5400 deaths and 30000 displaced', '08 Sep 2023', '10 Sep 2023', 'GLOFAS'], ['1102204', '2', '2', 'FL', '5300 deaths and 33000 displaced', '09 Sep 2023', '12 Sep 2023', 'GLOFAS']]\n",
      "0 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1102204', '2', '5300', '33000', 'Darnah, Susah, Derna, Benghazi, Darnah', 'Libya', '08 Sep - 14 Sep', 'This flood is expected to have a high humanitarian impact based on the magnitude and the affected population and their vulnerability.']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_0.csv\n",
      "1 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1102204', '2', 'death', '5300', 'Libya', 'Darnah, Susah, Derna, Benghazi'], ['1102204', '2', 'missing', '10000', 'Libya', 'Susah, Benghazi, Derna, Darnah']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_1.csv\n",
      "2 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[['1102204', '2', 'displaced', '33000', 'Libya', 'Benghazi, Darnah, Susah, Derna']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_2.csv\n",
      "3 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6']\n",
      "[]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_3.csv\n",
      "4 ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "[['1102204', '2', '1', 'FL', '5400 deaths and 30000 displaced', '08 Sep 2023', '10 Sep 2023', 'GLOFAS'], ['1102204', '2', '2', 'FL', '5300 deaths and 33000 displaced', '09 Sep 2023', '12 Sep 2023', 'GLOFAS']]\n",
      "Data appended to D:\\Web Scraping\\Web-Scraping\\CSV\\Floods_4.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
